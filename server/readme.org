* Usage

#+begin_src common-lisp
(async-py-eval "[1, 2, [True, False], {3: 4}, \"hello\"]")
;; => #(1 2 #(T NIL) #<HASH-TABLE :TEST EQUALP :COUNT 1 {7008B7FF43}> "hello")
#+end_src

* current problem

FastAPI can handle around 200 requests per second.

However, python cannot afford too many threads at a time. So we
shouldn't make say 10k requests during a short period of time.

For larger data (e.g. gigantic matrices), we can use shared
memory in the future.

To define variables or functions with execution.. we have a
problem. Currently, a work around is to use =app.x = 3= or =app.f =
(lambda x: x)=. But I'd like to see a more general and efficient
way. I should take a look at how py4cl2 does it.

** NOTE: shared memory communication

For sharing larger objects between Lisp and Python, we can use
shared memory (e.g. [[https://sr.ht/~shunter/posix-shm/][posix-shm: POSIX shared memory bindings for
Common Lisp]]). For usual communication, lets ditch FastAPI and
try ZeroMQ.

** NOTE: CL-ZMQ can't be loaded correctly

CFFI/GROVEL.. I don't know how to fix

